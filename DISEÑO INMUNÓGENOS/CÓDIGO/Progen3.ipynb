{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AIAB_TAnGxM"
      },
      "source": [
        "# 1. GENERACIÓN DE SECUENCIAS CON PROGEN3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI7V7MQH7Aot",
        "outputId": "8bf65e9f-c208-4af9-8409-7b607abd530a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'progen3'...\n",
            "remote: Enumerating objects: 65, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 65 (delta 13), reused 48 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (65/65), 70.86 KiB | 1.45 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Profluent-AI/progen3.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haAvPUiWS4uW",
        "outputId": "835ac300-cd7a-4c89-d283-cc1e6be8ca1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/progen3\n"
          ]
        }
      ],
      "source": [
        "%cd /content/progen3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBGrisbm7DN4",
        "outputId": "826eb4be-ca23-4b9c-876b-96ba7f41a3ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/progen3\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from progen3==0.1.0) (1.6.0)\n",
            "Collecting biopython (from progen3==0.1.0)\n",
            "  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from progen3==0.1.0) (8.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from progen3==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from progen3==0.1.0) (24.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from progen3==0.1.0) (1.15.3)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from progen3==0.1.0) (0.21.1)\n",
            "Collecting torch<2.5.2,>=2.5.0 (from progen3==0.1.0)\n",
            "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from progen3==0.1.0) (4.67.1)\n",
            "Collecting transformers<4.49,>=4.42 (from progen3==0.1.0)\n",
            "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.0->progen3==0.1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.0->progen3==0.1.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.0->progen3==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.0->progen3==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.0->progen3==0.1.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.5.2,>=2.5.0->progen3==0.1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.5.2,>=2.5.0->progen3==0.1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.5.2,>=2.5.0->progen3==0.1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.5.2,>=2.5.0->progen3==0.1.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.5.2,>=2.5.0->progen3==0.1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.5.2,>=2.5.0->progen3==0.1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<2.5.2,>=2.5.0->progen3==0.1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.5.2,>=2.5.0->progen3==0.1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.5.2,>=2.5.0->progen3==0.1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.0->progen3==0.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.0->progen3==0.1.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.5.2,>=2.5.0->progen3==0.1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch<2.5.2,>=2.5.0->progen3==0.1.0)\n",
            "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.0->progen3==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.5.2,>=2.5.0->progen3==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers<4.49,>=4.42->progen3==0.1.0) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<4.49,>=4.42->progen3==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<4.49,>=4.42->progen3==0.1.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers<4.49,>=4.42->progen3==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<4.49,>=4.42->progen3==0.1.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers<4.49,>=4.42->progen3==0.1.0) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<4.49,>=4.42->progen3==0.1.0) (0.5.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->progen3==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->progen3==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->progen3==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->progen3==0.1.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->progen3==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.5.2,>=2.5.0->progen3==0.1.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<4.49,>=4.42->progen3==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<4.49,>=4.42->progen3==0.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<4.49,>=4.42->progen3==0.1.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<4.49,>=4.42->progen3==0.1.0) (2025.4.26)\n",
            "Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m138.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: progen3\n",
            "  Building editable for progen3 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progen3: filename=progen3-0.1.0-py3-none-any.whl size=5215 sha256=85f46ccf968f56a9cdb792687af46e2c65ac9aa355a08cc847a0a6695e40bbbc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-90roabzp/wheels/d0/e4/fd/562b3e240e3dd11e10df93a34c6c2ac5d37aa1b81894088920\n",
            "Successfully built progen3\n",
            "Installing collected packages: triton, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, biopython, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, transformers, torch, progen3\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.5.1 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed biopython-1.85 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 progen3-0.1.0 torch-2.5.1 transformers-4.48.3 triton-3.1.0\n",
            "Collecting megablocks==0.7.0 (from megablocks[gg]==0.7.0)\n",
            "  Downloading megablocks-0.7.0.tar.gz (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.21.5 in /usr/local/lib/python3.11/dist-packages (from megablocks==0.7.0->megablocks[gg]==0.7.0) (2.0.2)\n",
            "Collecting packaging<24.2,>=21.3.0 (from megablocks==0.7.0->megablocks[gg]==0.7.0)\n",
            "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: torch<2.5.2,>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from megablocks==0.7.0->megablocks[gg]==0.7.0) (2.5.1)\n",
            "Requirement already satisfied: triton>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from megablocks==0.7.0->megablocks[gg]==0.7.0) (3.1.0)\n",
            "Collecting stanford-stk==0.7.1 (from megablocks==0.7.0->megablocks[gg]==0.7.0)\n",
            "  Downloading stanford_stk-0.7.1.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting grouped-gemm==0.1.6 (from megablocks[gg]==0.7.0)\n",
            "  Downloading grouped_gemm-0.1.6.tar.gz (978 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.2/978.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.5.2,>=2.5.1->megablocks==0.7.0->megablocks[gg]==0.7.0) (3.0.2)\n",
            "Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: megablocks, grouped-gemm, stanford-stk\n",
            "  Building wheel for megablocks (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for megablocks: filename=megablocks-0.7.0-cp311-cp311-linux_x86_64.whl size=527361 sha256=63a1b6e2ff7104f29edd0725c4c3c4b21342f6969dbb6b4a907ba47d4d04ca55\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/34/a2/90b67d07be4424327b9a487cc2cd765016f8f2df9362b294f4\n",
            "  Building wheel for grouped-gemm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grouped-gemm: filename=grouped_gemm-0.1.6-cp311-cp311-linux_x86_64.whl size=271256 sha256=fb1e8d2c0b30f0f8aa2949f1b520511ef270d12d805b595766a858cbc2a00bce\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/b1/34/1b3ea016ec03058708f28ac4dde331faefc51f4d7eeb87f8ec\n",
            "  Building wheel for stanford-stk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stanford-stk: filename=stanford_stk-0.7.1-py3-none-any.whl size=21520 sha256=6cc389194cdba8778e6da2fd5f74758d845d5d2ffeb05040d1977f4a3e6b43ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/f6/a7/d791540a9c4e0e90e9b320f639d0a1d13e6b62717a16ecfd98\n",
            "Successfully built megablocks grouped-gemm stanford-stk\n",
            "Installing collected packages: grouped-gemm, packaging, stanford-stk, megablocks\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 24.1 which is incompatible.\n",
            "google-cloud-bigquery 3.32.0 requires packaging>=24.2.0, but you have packaging 24.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed grouped-gemm-0.1.6 megablocks-0.7.0 packaging-24.1 stanford-stk-0.7.1\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.5.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187815463 sha256=d944fc7d2f962bce83fc4708c2fc0c21eaf8255962a0b350ae919362a51b7ef2\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.7.4.post1\n"
          ]
        }
      ],
      "source": [
        "!bash setup.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KalusZKuigOu",
        "outputId": "83681418-1b11-4b8d-af65-6121fb4f3a35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 2.5.1\n",
            "Uninstalling torch-2.5.1:\n",
            "  Successfully uninstalled torch-2.5.1\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Found existing installation: flash_attn 2.7.4.post1\n",
            "Uninstalling flash_attn-2.7.4.post1:\n",
            "  Successfully uninstalled flash_attn-2.7.4.post1\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m121.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torchvision>=0.11, which is not installed.\n",
            "timm 1.0.15 requires torchvision, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.0/768.0 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.7/239.7 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.6.0.dev20241112+cu121 which is incompatible.\n",
            "progen3 0.1.0 requires torch<2.5.2,>=2.5.0, but you have torch 2.6.0.dev20241112+cu121 which is incompatible.\n",
            "megablocks 0.7.0 requires torch<2.5.2,>=2.5.1, but you have torch 2.6.0.dev20241112+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Desinstala binarios pre-cargados por Colab\n",
        "!pip uninstall -y torch torchvision torchaudio flash-attn\n",
        "\n",
        "# PyTorch 2.5.1 + CUDA 12.1\n",
        "!pip install --quiet --upgrade \\\n",
        "  torch==2.5.1+cu121 torchaudio==2.5.1+cu121 \\\n",
        "  --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# TorchVision nightly compatible con Torch 2.5\n",
        "!pip install --quiet --pre --upgrade \\\n",
        "  torchvision --index-url https://download.pytorch.org/whl/nightly/cu121\n",
        "\n",
        "# Flash-Attention 2 compilado para Torch 2.5\n",
        "!pip install --quiet flash-attn --no-build-isolation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_eMZey3iiOl",
        "outputId": "8c3e5734-e21b-40ab-ea33-f240ea26cb46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA disponible: True |  GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "import torch, os, subprocess, textwrap, sys\n",
        "print(\"CUDA disponible:\", torch.cuda.is_available(), \"|  GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"-\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "H66m9yqLimbv",
        "outputId": "d5d1eb53-99b9-4b2a-bc02-739332508b38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-05-25 22:05:59.890968: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-25 22:05:59.909092: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1748210759.931344    7551 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1748210759.938043    7551 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-25 22:05:59.960062: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/flash_attn/ops/triton/layer_norm.py:984: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/usr/local/lib/python3.11/dist-packages/flash_attn/ops/triton/layer_norm.py:1043: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "WARNING:progen3.tools.utils:Model Profluent-Bio/progen3-3B not in AVAILABLE_MODELS; assuming its a local path.\n",
            "config.json: 100% 1.24k/1.24k [00:00<00:00, 8.43MB/s]\n",
            "model.safetensors.index.json: 100% 23.4k/23.4k [00:00<00:00, 93.4MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/5.00G [00:00<02:05, 39.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/5.00G [00:00<01:28, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/5.00G [00:00<01:10, 70.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/5.00G [00:00<00:50, 98.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/5.00G [00:00<00:50, 97.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 83.9M/5.00G [00:00<00:52, 94.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 94.4M/5.00G [00:01<00:53, 91.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 105M/5.00G [00:01<00:54, 90.0MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 115M/5.00G [00:01<00:55, 87.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 126M/5.00G [00:01<00:55, 87.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 136M/5.00G [00:01<00:55, 87.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 147M/5.00G [00:01<00:56, 86.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 157M/5.00G [00:01<00:56, 85.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 168M/5.00G [00:01<00:56, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 178M/5.00G [00:02<00:57, 84.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 189M/5.00G [00:02<00:57, 83.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 199M/5.00G [00:02<00:59, 80.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 210M/5.00G [00:02<00:58, 81.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 220M/5.00G [00:02<00:57, 82.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 231M/5.00G [00:02<00:57, 83.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 241M/5.00G [00:02<00:56, 83.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 252M/5.00G [00:02<00:56, 84.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 262M/5.00G [00:03<00:56, 84.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 273M/5.00G [00:03<00:55, 84.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 283M/5.00G [00:03<00:56, 83.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 294M/5.00G [00:03<00:55, 84.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 304M/5.00G [00:03<00:56, 83.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 315M/5.00G [00:03<00:55, 84.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 325M/5.00G [00:03<00:55, 84.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 336M/5.00G [00:03<00:55, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 346M/5.00G [00:04<00:54, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 357M/5.00G [00:04<00:54, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 367M/5.00G [00:04<00:54, 85.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 377M/5.00G [00:04<00:54, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 388M/5.00G [00:04<00:54, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 398M/5.00G [00:04<00:54, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 409M/5.00G [00:04<00:53, 85.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 419M/5.00G [00:04<00:53, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 430M/5.00G [00:05<00:53, 85.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 440M/5.00G [00:05<00:53, 85.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 451M/5.00G [00:05<00:53, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 461M/5.00G [00:05<00:53, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 472M/5.00G [00:05<00:52, 85.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 482M/5.00G [00:05<00:52, 85.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 493M/5.00G [00:05<00:52, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 503M/5.00G [00:05<00:52, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 514M/5.00G [00:06<00:52, 85.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 524M/5.00G [00:06<00:52, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 535M/5.00G [00:06<00:52, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 545M/5.00G [00:06<00:52, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 556M/5.00G [00:06<00:52, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 566M/5.00G [00:06<00:52, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 577M/5.00G [00:06<00:52, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 587M/5.00G [00:06<00:52, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 598M/5.00G [00:07<00:54, 81.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 608M/5.00G [00:07<00:53, 82.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 619M/5.00G [00:07<00:53, 82.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 629M/5.00G [00:07<00:53, 81.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 640M/5.00G [00:07<00:52, 82.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 650M/5.00G [00:07<00:52, 83.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 661M/5.00G [00:07<00:51, 83.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 671M/5.00G [00:07<00:51, 84.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 682M/5.00G [00:08<00:51, 83.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 692M/5.00G [00:08<00:51, 84.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 703M/5.00G [00:08<00:50, 84.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 713M/5.00G [00:08<00:50, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 724M/5.00G [00:08<00:50, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 734M/5.00G [00:08<00:50, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 744M/5.00G [00:08<00:50, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 755M/5.00G [00:08<00:50, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 765M/5.00G [00:09<00:49, 85.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 776M/5.00G [00:09<00:49, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 786M/5.00G [00:09<00:49, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 797M/5.00G [00:09<00:49, 85.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 807M/5.00G [00:09<00:49, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 818M/5.00G [00:09<00:49, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 828M/5.00G [00:09<00:48, 85.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 839M/5.00G [00:09<00:48, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 849M/5.00G [00:10<00:48, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 860M/5.00G [00:10<00:50, 81.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 870M/5.00G [00:10<00:57, 72.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 881M/5.00G [00:10<00:53, 77.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 891M/5.00G [00:10<00:55, 74.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 912M/5.00G [00:10<00:46, 87.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 923M/5.00G [00:10<00:46, 87.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 933M/5.00G [00:11<00:50, 80.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 944M/5.00G [00:11<00:51, 78.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 965M/5.00G [00:11<00:47, 84.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 986M/5.00G [00:11<00:43, 92.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 996M/5.00G [00:11<00:44, 90.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.01G/5.00G [00:11<00:44, 89.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.02G/5.00G [00:12<00:45, 87.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.03G/5.00G [00:12<00:45, 87.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.04G/5.00G [00:12<00:46, 85.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.05G/5.00G [00:12<00:46, 85.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.06G/5.00G [00:12<00:46, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.07G/5.00G [00:12<00:46, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.08G/5.00G [00:12<00:46, 84.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.09G/5.00G [00:12<00:46, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.10G/5.00G [00:13<00:45, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.11G/5.00G [00:13<00:45, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.12G/5.00G [00:13<00:45, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.13G/5.00G [00:13<00:45, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/5.00G [00:13<00:45, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.15G/5.00G [00:13<01:04, 60.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.17G/5.00G [00:13<00:46, 82.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.20G/5.00G [00:14<00:40, 93.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.21G/5.00G [00:14<00:41, 91.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.22G/5.00G [00:14<00:42, 89.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.23G/5.00G [00:14<00:42, 88.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.24G/5.00G [00:14<00:42, 87.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.25G/5.00G [00:14<00:43, 86.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.26G/5.00G [00:14<00:43, 86.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.27G/5.00G [00:15<00:43, 86.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.28G/5.00G [00:15<00:43, 85.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.29G/5.00G [00:15<00:43, 85.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.30G/5.00G [00:15<00:43, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.31G/5.00G [00:15<00:43, 85.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.32G/5.00G [00:15<00:43, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.33G/5.00G [00:15<00:43, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.34G/5.00G [00:15<00:43, 84.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.35G/5.00G [00:16<00:43, 84.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.36G/5.00G [00:16<00:43, 83.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.37G/5.00G [00:16<00:43, 83.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.38G/5.00G [00:16<00:43, 82.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.39G/5.00G [00:16<00:43, 83.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.41G/5.00G [00:16<00:43, 83.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.42G/5.00G [00:16<00:43, 82.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.43G/5.00G [00:16<00:42, 83.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.44G/5.00G [00:17<00:42, 83.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.45G/5.00G [00:17<00:42, 83.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.46G/5.00G [00:17<00:41, 84.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.47G/5.00G [00:17<00:41, 84.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/5.00G [00:17<00:41, 84.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.49G/5.00G [00:17<00:41, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.50G/5.00G [00:17<00:41, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.51G/5.00G [00:17<00:41, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.52G/5.00G [00:18<00:41, 84.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.53G/5.00G [00:18<00:40, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.54G/5.00G [00:18<00:40, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.55G/5.00G [00:18<00:40, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.56G/5.00G [00:18<00:40, 85.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.57G/5.00G [00:18<00:40, 85.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.58G/5.00G [00:18<00:40, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.59G/5.00G [00:18<00:39, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.60G/5.00G [00:18<00:39, 85.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.61G/5.00G [00:19<00:39, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.63G/5.00G [00:19<00:39, 85.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.64G/5.00G [00:19<00:39, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.65G/5.00G [00:19<00:39, 84.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.66G/5.00G [00:19<00:39, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.67G/5.00G [00:19<00:39, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.68G/5.00G [00:19<00:38, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.69G/5.00G [00:19<00:38, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.70G/5.00G [00:20<00:38, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.71G/5.00G [00:20<00:38, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.72G/5.00G [00:20<00:38, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.73G/5.00G [00:20<00:38, 84.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.74G/5.00G [00:20<00:38, 83.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.75G/5.00G [00:20<00:38, 83.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.76G/5.00G [00:20<00:38, 83.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.77G/5.00G [00:20<00:39, 82.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.78G/5.00G [00:21<00:38, 83.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.79G/5.00G [00:21<00:38, 83.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.80G/5.00G [00:21<00:38, 83.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.81G/5.00G [00:21<00:38, 83.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.82G/5.00G [00:21<00:39, 80.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.84G/5.00G [00:21<00:39, 81.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.85G/5.00G [00:21<00:40, 78.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.87G/5.00G [00:22<00:39, 80.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.88G/5.00G [00:22<00:41, 74.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.89G/5.00G [00:22<00:39, 78.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.90G/5.00G [00:22<00:38, 81.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.92G/5.00G [00:22<00:34, 90.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.93G/5.00G [00:22<00:35, 86.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.95G/5.00G [00:23<00:32, 92.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.96G/5.00G [00:23<00:33, 91.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.97G/5.00G [00:23<00:33, 89.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.98G/5.00G [00:23<00:34, 88.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.99G/5.00G [00:23<00:34, 87.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 2.00G/5.00G [00:23<00:34, 87.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 2.01G/5.00G [00:23<00:34, 86.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.02G/5.00G [00:23<00:34, 85.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.03G/5.00G [00:24<00:34, 85.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.04G/5.00G [00:24<00:34, 85.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.06G/5.00G [00:24<00:34, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.07G/5.00G [00:24<00:34, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.08G/5.00G [00:24<00:34, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.09G/5.00G [00:24<00:34, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.10G/5.00G [00:24<00:34, 84.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.11G/5.00G [00:24<00:34, 83.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.12G/5.00G [00:25<00:46, 61.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/5.00G [00:25<00:31, 89.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.16G/5.00G [00:25<00:32, 88.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.17G/5.00G [00:25<00:32, 87.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.18G/5.00G [00:25<00:32, 86.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.19G/5.00G [00:25<00:33, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.20G/5.00G [00:26<00:32, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.21G/5.00G [00:26<00:32, 84.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.22G/5.00G [00:26<00:32, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.23G/5.00G [00:26<00:32, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.24G/5.00G [00:26<00:32, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.25G/5.00G [00:26<00:32, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.26G/5.00G [00:26<00:32, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/5.00G [00:26<00:31, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.29G/5.00G [00:27<00:32, 84.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.30G/5.00G [00:27<00:31, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.31G/5.00G [00:27<00:31, 85.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.32G/5.00G [00:27<00:31, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.33G/5.00G [00:27<00:31, 85.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.34G/5.00G [00:27<00:31, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.35G/5.00G [00:27<00:31, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.36G/5.00G [00:27<00:31, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.37G/5.00G [00:28<00:30, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.38G/5.00G [00:28<00:30, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.39G/5.00G [00:28<00:31, 84.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.40G/5.00G [00:28<00:30, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.41G/5.00G [00:28<00:30, 85.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.42G/5.00G [00:28<00:30, 85.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.43G/5.00G [00:28<00:30, 85.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.44G/5.00G [00:28<00:29, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.45G/5.00G [00:29<00:30, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.46G/5.00G [00:29<00:29, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.47G/5.00G [00:29<00:30, 83.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.49G/5.00G [00:29<00:29, 84.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.50G/5.00G [00:29<00:29, 84.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.51G/5.00G [00:29<00:29, 83.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.52G/5.00G [00:29<00:29, 84.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.53G/5.00G [00:29<00:29, 83.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.54G/5.00G [00:30<00:29, 83.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.55G/5.00G [00:30<00:29, 82.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.56G/5.00G [00:30<00:29, 82.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.57G/5.00G [00:30<00:29, 82.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.58G/5.00G [00:30<00:29, 83.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.59G/5.00G [00:30<00:28, 83.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.60G/5.00G [00:30<00:28, 84.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.61G/5.00G [00:30<00:28, 84.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.62G/5.00G [00:31<00:28, 84.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.63G/5.00G [00:31<00:27, 84.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.64G/5.00G [00:31<00:28, 83.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.65G/5.00G [00:31<00:27, 85.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.66G/5.00G [00:31<00:27, 85.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.67G/5.00G [00:31<00:27, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.68G/5.00G [00:31<00:27, 85.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.69G/5.00G [00:31<00:27, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.71G/5.00G [00:32<00:26, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.72G/5.00G [00:32<00:26, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.73G/5.00G [00:32<00:26, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.74G/5.00G [00:32<00:26, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.75G/5.00G [00:32<00:26, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.76G/5.00G [00:32<00:26, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.77G/5.00G [00:32<00:26, 84.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.78G/5.00G [00:32<00:26, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.79G/5.00G [00:33<00:28, 76.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.80G/5.00G [00:33<00:31, 68.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.81G/5.00G [00:33<00:29, 74.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.82G/5.00G [00:33<00:31, 69.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.83G/5.00G [00:33<00:29, 72.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.85G/5.00G [00:33<00:27, 78.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.86G/5.00G [00:34<00:27, 78.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.87G/5.00G [00:34<00:27, 76.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.88G/5.00G [00:34<00:28, 74.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.90G/5.00G [00:34<00:21, 96.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.93G/5.00G [00:34<00:19, 107MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.95G/5.00G [00:34<00:21, 96.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.96G/5.00G [00:35<00:21, 93.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.97G/5.00G [00:35<00:22, 91.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.98G/5.00G [00:35<00:22, 89.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.99G/5.00G [00:35<00:22, 88.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 3.00G/5.00G [00:35<00:22, 87.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 3.01G/5.00G [00:35<00:22, 86.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 3.02G/5.00G [00:35<00:22, 86.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.03G/5.00G [00:35<00:22, 85.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.04G/5.00G [00:36<00:22, 85.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.05G/5.00G [00:36<00:22, 85.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.06G/5.00G [00:36<00:22, 85.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.07G/5.00G [00:36<00:22, 84.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.08G/5.00G [00:36<00:22, 85.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.09G/5.00G [00:36<00:22, 85.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.10G/5.00G [00:36<00:22, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.11G/5.00G [00:36<00:22, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.12G/5.00G [00:37<00:21, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.14G/5.00G [00:37<00:21, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.15G/5.00G [00:37<00:21, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.16G/5.00G [00:37<00:21, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.17G/5.00G [00:37<00:21, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.18G/5.00G [00:37<00:21, 84.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.19G/5.00G [00:37<00:21, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.20G/5.00G [00:37<00:21, 84.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.21G/5.00G [00:38<00:21, 83.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.22G/5.00G [00:38<00:20, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.23G/5.00G [00:38<00:20, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.24G/5.00G [00:38<00:20, 84.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.25G/5.00G [00:38<00:20, 84.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.26G/5.00G [00:38<00:20, 84.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.27G/5.00G [00:38<00:20, 84.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.28G/5.00G [00:38<00:20, 83.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.29G/5.00G [00:39<00:20, 82.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.30G/5.00G [00:39<00:20, 83.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.31G/5.00G [00:39<00:20, 82.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.32G/5.00G [00:39<00:19, 83.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.33G/5.00G [00:39<00:19, 83.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.34G/5.00G [00:39<00:19, 83.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.36G/5.00G [00:39<00:19, 84.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.37G/5.00G [00:39<00:19, 84.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.38G/5.00G [00:40<00:19, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.39G/5.00G [00:40<00:18, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.40G/5.00G [00:40<00:18, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.41G/5.00G [00:40<00:18, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.42G/5.00G [00:40<00:18, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.43G/5.00G [00:40<00:18, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.44G/5.00G [00:40<00:18, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.45G/5.00G [00:40<00:19, 80.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.46G/5.00G [00:41<00:18, 81.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.47G/5.00G [00:41<00:18, 82.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.48G/5.00G [00:41<00:18, 83.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.49G/5.00G [00:41<00:18, 83.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.50G/5.00G [00:41<00:17, 84.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.51G/5.00G [00:41<00:17, 84.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.52G/5.00G [00:41<00:17, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.53G/5.00G [00:41<00:17, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.54G/5.00G [00:41<00:17, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.55G/5.00G [00:42<00:16, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.57G/5.00G [00:42<00:16, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.58G/5.00G [00:42<00:16, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.59G/5.00G [00:42<00:16, 85.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.60G/5.00G [00:42<00:16, 83.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.61G/5.00G [00:42<00:16, 83.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.62G/5.00G [00:42<00:16, 84.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.63G/5.00G [00:43<00:17, 78.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.65G/5.00G [00:43<00:15, 86.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.66G/5.00G [00:43<00:15, 86.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.67G/5.00G [00:43<00:15, 86.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.68G/5.00G [00:43<00:15, 85.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.69G/5.00G [00:43<00:15, 85.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.70G/5.00G [00:43<00:15, 82.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.71G/5.00G [00:43<00:14, 86.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.72G/5.00G [00:44<00:14, 85.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.73G/5.00G [00:44<00:14, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.74G/5.00G [00:44<00:14, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.75G/5.00G [00:44<00:16, 77.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.76G/5.00G [00:44<00:14, 83.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.77G/5.00G [00:44<00:13, 88.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.79G/5.00G [00:44<00:15, 80.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.80G/5.00G [00:45<00:15, 76.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.81G/5.00G [00:45<00:14, 79.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.82G/5.00G [00:45<00:13, 85.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.83G/5.00G [00:45<00:13, 86.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.84G/5.00G [00:45<00:14, 80.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.85G/5.00G [00:45<00:14, 77.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.86G/5.00G [00:45<00:14, 80.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.88G/5.00G [00:45<00:12, 91.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.89G/5.00G [00:46<00:12, 89.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.90G/5.00G [00:46<00:18, 59.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.93G/5.00G [00:46<00:11, 95.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.95G/5.00G [00:46<00:11, 91.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.96G/5.00G [00:46<00:11, 90.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/5.00G [00:47<00:11, 88.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.98G/5.00G [00:47<00:11, 87.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 4.00G/5.00G [00:47<00:11, 87.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 4.01G/5.00G [00:47<00:11, 86.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 4.02G/5.00G [00:47<00:11, 86.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.03G/5.00G [00:47<00:11, 85.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.04G/5.00G [00:47<00:11, 85.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.05G/5.00G [00:47<00:11, 85.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.06G/5.00G [00:48<00:10, 85.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.07G/5.00G [00:48<00:10, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.08G/5.00G [00:48<00:10, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.09G/5.00G [00:48<00:10, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.10G/5.00G [00:48<00:10, 82.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.11G/5.00G [00:48<00:10, 83.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.12G/5.00G [00:48<00:10, 83.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.13G/5.00G [00:48<00:10, 84.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.14G/5.00G [00:49<00:10, 84.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.15G/5.00G [00:49<00:09, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.16G/5.00G [00:49<00:09, 85.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.17G/5.00G [00:49<00:09, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.18G/5.00G [00:49<00:09, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.19G/5.00G [00:49<00:09, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.20G/5.00G [00:49<00:09, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.22G/5.00G [00:49<00:09, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.23G/5.00G [00:50<00:09, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.24G/5.00G [00:50<00:08, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.25G/5.00G [00:50<00:08, 84.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.26G/5.00G [00:50<00:08, 83.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.27G/5.00G [00:50<00:08, 82.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.28G/5.00G [00:50<00:08, 83.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.29G/5.00G [00:50<00:08, 83.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.30G/5.00G [00:50<00:08, 84.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.31G/5.00G [00:51<00:08, 83.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.32G/5.00G [00:51<00:08, 84.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.33G/5.00G [00:51<00:07, 84.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.34G/5.00G [00:51<00:07, 84.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.35G/5.00G [00:51<00:07, 84.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.36G/5.00G [00:51<00:07, 84.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.37G/5.00G [00:51<00:07, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.38G/5.00G [00:51<00:07, 84.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.39G/5.00G [00:52<00:08, 70.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.40G/5.00G [00:52<00:07, 74.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.41G/5.00G [00:52<00:07, 77.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.42G/5.00G [00:52<00:07, 79.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.44G/5.00G [00:52<00:06, 81.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.45G/5.00G [00:52<00:06, 82.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.46G/5.00G [00:52<00:06, 83.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.47G/5.00G [00:53<00:06, 83.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.48G/5.00G [00:53<00:06, 84.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.49G/5.00G [00:53<00:06, 84.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.50G/5.00G [00:53<00:05, 84.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.51G/5.00G [00:53<00:05, 84.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.52G/5.00G [00:53<00:05, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.53G/5.00G [00:53<00:05, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.54G/5.00G [00:53<00:05, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.55G/5.00G [00:53<00:05, 84.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.56G/5.00G [00:54<00:05, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.57G/5.00G [00:54<00:04, 85.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.58G/5.00G [00:54<00:04, 84.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.59G/5.00G [00:54<00:04, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.60G/5.00G [00:54<00:04, 85.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.61G/5.00G [00:54<00:04, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.62G/5.00G [00:54<00:04, 85.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.63G/5.00G [00:54<00:04, 84.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.65G/5.00G [00:55<00:04, 85.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.66G/5.00G [00:55<00:03, 85.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.67G/5.00G [00:55<00:03, 83.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.68G/5.00G [00:55<00:03, 86.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.69G/5.00G [00:55<00:03, 78.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.70G/5.00G [00:55<00:03, 79.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.71G/5.00G [00:55<00:03, 80.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.72G/5.00G [00:56<00:03, 72.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.73G/5.00G [00:56<00:03, 75.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.74G/5.00G [00:56<00:03, 79.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.75G/5.00G [00:56<00:03, 73.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.76G/5.00G [00:56<00:03, 72.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.77G/5.00G [00:56<00:02, 78.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.79G/5.00G [00:56<00:02, 88.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.81G/5.00G [00:57<00:02, 91.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.83G/5.00G [00:57<00:01, 93.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.84G/5.00G [00:57<00:01, 91.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.85G/5.00G [00:57<00:01, 90.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.87G/5.00G [00:57<00:01, 88.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.88G/5.00G [00:57<00:01, 87.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.89G/5.00G [00:57<00:01, 86.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.90G/5.00G [00:58<00:01, 86.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.91G/5.00G [00:58<00:01, 86.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.92G/5.00G [00:58<00:00, 85.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.93G/5.00G [00:58<00:00, 85.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.94G/5.00G [00:58<00:00, 85.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.95G/5.00G [00:58<00:00, 85.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.96G/5.00G [00:58<00:00, 84.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.97G/5.00G [00:58<00:00, 83.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.98G/5.00G [00:59<00:00, 81.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 5.00G/5.00G [00:59<00:00, 84.3MB/s]\n",
            "Downloading shards:  50% 1/2 [00:59<00:59, 59.53s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/984M [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 10.5M/984M [00:00<00:15, 64.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 21.0M/984M [00:00<00:13, 73.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 41.9M/984M [00:00<00:10, 89.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 52.4M/984M [00:00<00:10, 88.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 62.9M/984M [00:00<00:10, 86.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 73.4M/984M [00:00<00:10, 86.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 83.9M/984M [00:00<00:10, 86.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 94.4M/984M [00:01<00:10, 86.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 105M/984M [00:01<00:10, 86.1MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 115M/984M [00:01<00:10, 86.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 126M/984M [00:01<00:10, 85.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 136M/984M [00:01<00:09, 85.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 147M/984M [00:01<00:09, 85.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 157M/984M [00:01<00:09, 85.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 168M/984M [00:01<00:09, 85.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 178M/984M [00:02<00:09, 85.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 189M/984M [00:02<00:09, 85.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 199M/984M [00:02<00:09, 85.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 210M/984M [00:02<00:09, 85.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 220M/984M [00:02<00:08, 85.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 231M/984M [00:02<00:08, 85.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 241M/984M [00:02<00:08, 85.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 252M/984M [00:02<00:08, 85.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 262M/984M [00:03<00:08, 85.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 273M/984M [00:03<00:08, 85.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 283M/984M [00:03<00:08, 85.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 294M/984M [00:03<00:08, 85.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 304M/984M [00:03<00:07, 85.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 315M/984M [00:03<00:07, 84.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 325M/984M [00:03<00:07, 85.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 336M/984M [00:03<00:07, 82.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 346M/984M [00:04<00:07, 82.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 357M/984M [00:04<00:07, 83.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 367M/984M [00:04<00:07, 84.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 377M/984M [00:04<00:07, 83.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 388M/984M [00:04<00:07, 84.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 398M/984M [00:04<00:06, 84.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 409M/984M [00:04<00:06, 85.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 419M/984M [00:04<00:06, 85.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 430M/984M [00:05<00:06, 85.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 440M/984M [00:05<00:06, 85.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 451M/984M [00:05<00:06, 85.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 461M/984M [00:05<00:06, 85.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 472M/984M [00:05<00:05, 86.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 482M/984M [00:05<00:05, 85.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 493M/984M [00:05<00:05, 85.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 503M/984M [00:05<00:05, 85.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 514M/984M [00:06<00:05, 85.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 524M/984M [00:06<00:05, 85.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 535M/984M [00:06<00:05, 85.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 545M/984M [00:06<00:05, 85.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 556M/984M [00:06<00:05, 85.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 566M/984M [00:06<00:04, 85.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 577M/984M [00:06<00:04, 84.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 587M/984M [00:06<00:05, 72.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 608M/984M [00:07<00:04, 87.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 619M/984M [00:07<00:04, 86.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 629M/984M [00:07<00:04, 86.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 640M/984M [00:07<00:04, 85.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 650M/984M [00:07<00:03, 85.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 661M/984M [00:07<00:03, 85.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 671M/984M [00:07<00:03, 85.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 682M/984M [00:08<00:03, 84.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 692M/984M [00:08<00:03, 84.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 703M/984M [00:08<00:03, 85.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 713M/984M [00:08<00:03, 85.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 724M/984M [00:08<00:03, 85.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 734M/984M [00:08<00:02, 85.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 744M/984M [00:08<00:02, 85.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 755M/984M [00:08<00:02, 84.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 765M/984M [00:09<00:02, 84.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 776M/984M [00:09<00:02, 85.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 786M/984M [00:09<00:02, 85.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 797M/984M [00:09<00:02, 85.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 807M/984M [00:09<00:02, 85.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 818M/984M [00:09<00:01, 85.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 828M/984M [00:09<00:01, 85.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 839M/984M [00:09<00:01, 85.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 849M/984M [00:09<00:01, 86.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 860M/984M [00:10<00:01, 76.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 870M/984M [00:10<00:01, 73.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 881M/984M [00:10<00:01, 67.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 902M/984M [00:10<00:00, 82.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 923M/984M [00:10<00:00, 93.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 933M/984M [00:10<00:00, 92.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 944M/984M [00:11<00:00, 84.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 954M/984M [00:11<00:00, 81.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 965M/984M [00:11<00:00, 82.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 984M/984M [00:11<00:00, 85.1MB/s]\n",
            "Downloading shards: 100% 2/2 [01:11<00:00, 35.66s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  3.39it/s]\n",
            "generation_config.json: 100% 132/132 [00:00<00:00, 978kB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/distributed/fsdp/_init_utils.py:444: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.\n",
            "  warnings.warn(\n",
            "[rank0]: Traceback (most recent call last):\n",
            "[rank0]:   File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "[rank0]:   File \"<frozen runpy>\", line 88, in _run_code\n",
            "[rank0]:   File \"/content/progen3/src/progen3/tools/generate.py\", line 53, in <module>\n",
            "[rank0]:     generate()\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n",
            "[rank0]:     return f(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1442, in __call__\n",
            "[rank0]:     return self.main(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1363, in main\n",
            "[rank0]:     rv = self.invoke(ctx)\n",
            "[rank0]:          ^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1226, in invoke\n",
            "[rank0]:     return ctx.invoke(self.callback, **ctx.params)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 794, in invoke\n",
            "[rank0]:     return callback(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/progen3/src/progen3/tools/generate.py\", line 42, in generate\n",
            "[rank0]:     generator.run(prompt_file, output_dir, n_per_prompt)\n",
            "[rank0]:   File \"/content/progen3/src/progen3/generator.py\", line 138, in run\n",
            "[rank0]:     prompt_df = pd.read_csv(prompt_file)\n",
            "[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
            "[rank0]:     return _read(filepath_or_buffer, kwds)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
            "[rank0]:     parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
            "[rank0]:     self._engine = self._make_engine(f, self.engine)\n",
            "[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n",
            "[rank0]:     self.handles = get_handle(\n",
            "[rank0]:                    ^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\", line 873, in get_handle\n",
            "[rank0]:     handle = open(\n",
            "[rank0]:              ^^^^^\n",
            "[rank0]: FileNotFoundError: [Errno 2] No such file or directory: '/content/prompts.csv'\n",
            "E0525 22:07:21.456000 7528 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 7551) of binary: /usr/bin/python3\n",
            "E0525 22:07:21.457000 7528 torch/distributed/elastic/multiprocessing/errors/error_handler.py:141] no error file defined for parent, to copy child error file (/tmp/torchelastic_2pmp1e0b/none_e7ti9zl4/attempt_0/0/error.json)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/torchrun\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 919, in main\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 910, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "progen3.tools.generate FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2025-05-25_22:07:19\n",
            "  host      : 4016cab51087\n",
            "  rank      : 0 (local_rank: 0)\n",
            "  exitcode  : 1 (pid: 7551)\n",
            "  error_file: /tmp/torchelastic_2pmp1e0b/none_e7ti9zl4/attempt_0/0/error.json\n",
            "  traceback : Traceback (most recent call last):\n",
            "    File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n",
            "      return f(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^\n",
            "    File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1442, in __call__\n",
            "      return self.main(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1363, in main\n",
            "      rv = self.invoke(ctx)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "    File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1226, in invoke\n",
            "      return ctx.invoke(self.callback, **ctx.params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 794, in invoke\n",
            "      return callback(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    File \"/content/progen3/src/progen3/tools/generate.py\", line 42, in generate\n",
            "      generator.run(prompt_file, output_dir, n_per_prompt)\n",
            "    File \"/content/progen3/src/progen3/generator.py\", line 138, in run\n",
            "      prompt_df = pd.read_csv(prompt_file)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
            "      return _read(filepath_or_buffer, kwds)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
            "      parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
            "      self._engine = self._make_engine(f, self.engine)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n",
            "      self.handles = get_handle(\n",
            "                     ^^^^^^^^^^^\n",
            "    File \"/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\", line 873, in get_handle\n",
            "      handle = open(\n",
            "               ^^^^^\n",
            "  FileNotFoundError: [Errno 2] No such file or directory: '/content/prompts.csv'\n",
            "  \n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "!mkdir /content/drive/MyDrive/generation_outputs/\n",
        "!torchrun --nproc-per-node=1 -m progen3.tools.generate \\\n",
        "  --prompt-file  /content/prompts.csv \\\n",
        "  --output-dir   /content/drive/MyDrive/generation_outputs/ \\\n",
        "  --model-name   Profluent-Bio/progen3-3B\\\n",
        "  --n-per-prompt 10 \\\n",
        "  --fsdp \\\n",
        "  --temperature 1 \\\n",
        "  --top-p 0.8\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZZhyilBnMKd"
      },
      "source": [
        "# VALIDACIÓN DE SECUENCIA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNMCIYK6nTA8"
      },
      "outputs": [],
      "source": [
        "!pip install fair-esm\n",
        "!pip install tqdm biopython numpy\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Descripción:\n",
        " 1) Lee un FASTA de entrada.\n",
        " 2) Calcula para cada secuencia el score promedio (mean log-prob) con el modelo ESM.\n",
        " 3) Filtra según un cuantíl o umbral fijado en variables.\n",
        " 4) Escribe un FASTA con las secuencias que pasan el filtro y un CSV con id, score, passed.\n",
        "\"\"\"\n",
        "!cat /content/generation_outputs/*.seq.fasta > /content/seqs.fasta\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import esm\n",
        "from tqdm import tqdm\n",
        "from Bio import SeqIO\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def score_sequence(model, alphabet, seq, device):\n",
        "    # Filtrar caracteres no válidos para evitar KeyError\n",
        "    valid = set(alphabet.tok_to_idx.keys())\n",
        "    seq = ''.join([c for c in seq if c in valid])\n",
        "    if len(seq) == 0:\n",
        "        raise ValueError(\"Sequence contains no valid amino acids after filtering.\")\n",
        "    # Tokenizar y mover a device\n",
        "    # Tokenizar y mover a device\n",
        "    batch_converter = alphabet.get_batch_converter()\n",
        "    _, _, toks = batch_converter([(\"seq\", seq)])\n",
        "    toks = toks.to(device)\n",
        "    # Forward pass\n",
        "    with torch.no_grad():\n",
        "        out = model(toks, repr_layers=[], return_contacts=False)\n",
        "    logits = out[\"logits\"][0, 1:1+len(seq)]  # (L, vocab)\n",
        "    log_probs = F.log_softmax(logits, dim=-1)\n",
        "    token_ids = toks[0, 1:1+len(seq)]\n",
        "    pos_logps = log_probs[torch.arange(len(seq)), token_ids]\n",
        "    return pos_logps.mean().item()\n",
        "\n",
        "\n",
        "def main():\n",
        "    # --- Parámetros predefinidos ---\n",
        "    input_fasta   = \"/content/seqs.fasta\"\n",
        "    model_name    = \"esm1v_t33_650M_UR90S_1\"\n",
        "    device        = \"cuda\"\n",
        "    # Define un umbral fijo o un cuantíl\n",
        "    threshold   = -0.13\n",
        "    quantile     = 0.9\n",
        "    output_fasta  = \"passed.fasta\"\n",
        "    output_csv    = \"scores.csv\"\n",
        "    # -------------------------------\n",
        "\n",
        "    # Configura dispositivo\n",
        "    device = torch.device(device if torch.cuda.is_available() and device.startswith(\"cuda\") else \"cpu\")\n",
        "\n",
        "    # Cargar modelo y alfabeto\n",
        "    print(f\"[INFO] Cargando modelo {model_name} en {device}\")\n",
        "    model, alphabet = esm.pretrained.load_model_and_alphabet(model_name)\n",
        "    model = model.eval().to(device)\n",
        "\n",
        "    # Leer FASTA\n",
        "    records = list(SeqIO.parse(input_fasta, \"fasta\"))\n",
        "    print(f\"[INFO] {len(records)} secuencias cargadas desde {input_fasta}\")\n",
        "\n",
        "    # Calcular scores\n",
        "    results = []\n",
        "    for rec in tqdm(records, desc=\"Scoring\"):\n",
        "        # Limpiar secuencia: solo letras (A-Z)\n",
        "        raw_seq = str(rec.seq)\n",
        "        seq = ''.join(c for c in raw_seq if c.isalpha())\n",
        "        if not seq:\n",
        "            print(f\"[WARN] Secuencia {rec.id} vacía tras limpieza, se omite.\")\n",
        "            continue\n",
        "        score = score_sequence(model, alphabet, seq, device)\n",
        "        results.append((rec.id, rec.seq, score))\n",
        "\n",
        "    # Determinar umbral(rec.id, rec.seq, score))\n",
        "\n",
        "    # Determinar umbral\n",
        "    thr=-0.13\n",
        "\n",
        "    # Filtrar y escribir CSV y FASTA\n",
        "    passed_ids = []\n",
        "    with open(output_csv, \"w\") as csvf:\n",
        "        csvf.write(\"id,score,passed\")\n",
        "        for ident, seq, score in results:\n",
        "            passed = int(score >= thr)\n",
        "            csvf.write(f\"{ident},{score:.6f},{passed}/n\")\n",
        "            if passed:\n",
        "                passed_ids.append(ident)\n",
        "    # Escribir FASTA resultante\n",
        "    with open(output_fasta, \"w\") as fh:\n",
        "        for rec in records:\n",
        "            if rec.id in passed_ids:\n",
        "                SeqIO.write(rec, fh, \"fasta\")\n",
        "\n",
        "    print(f\"[DONE] {len(passed_ids)}/{len(results)} secuencias pasan el filtro\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFwbs-ELsg9O"
      },
      "outputs": [],
      "source": [
        "!mv /content/scores.csv /content/generation_outputs/\n",
        "!mv /content/passed.fasta /content/generation_outputs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6LZ4BQRufBD"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wq-AV2K0V17g"
      },
      "outputs": [],
      "source": [
        "input_fasta    = \"/content/sequences_progen3.fasta\"\n",
        "filter_csv     = \"/content/GPT_sequences_filter1.csv\"\n",
        "ESMthreshold   = -0.2\n",
        "conservate     = set()\n",
        "\n",
        "# 1) Lee el CSV y rellena el set de secuencias a conservar\n",
        "with open(filter_csv) as f:\n",
        "    # Si tu CSV tiene cabecera, descomenta la siguiente línea:\n",
        "    # next(f)\n",
        "    n=1\n",
        "    for line in f:\n",
        "        if n==1:\n",
        "          n=0\n",
        "          continue\n",
        "        ignorar,seq, score, ident = line.strip().split(\",\")\n",
        "        seq=seq.strip('\"').strip('\"')\n",
        "        score = float(score)\n",
        "        ident = float(ident)\n",
        "        # si identidad > 30% lo saltamos;\n",
        "        # si score < umbral lo guardamos:\n",
        "        if ident <= 35 and score > ESMthreshold:\n",
        "            conservate.add(seq)\n",
        "\n",
        "print(f\"Secuencias a conservar: {len(conservate)}\")\n",
        "\n",
        "# 2) Filtra el FASTA\n",
        "output_fasta = \"/content/progen3_sequences_conserved.fasta\"\n",
        "with open(input_fasta) as fin, open(output_fasta, \"w\") as fout:\n",
        "    write = False\n",
        "    for line in fin:\n",
        "        if line.startswith(\">\"):\n",
        "            # Extrae sólo el ID (hasta el primer espacio)\n",
        "            seqid = line[1:].strip().split()[0]\n",
        "            write = (seqid in conservate)\n",
        "        if write:\n",
        "            fout.write(line)\n",
        "\n",
        "print(f\"Escrito el FASTA filtrado en: {output_fasta}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsb5rjegfdNT"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/BernhoferM/TMbed.git\n",
        "#!/usr/bin/env python3\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "La pipeline hace:\n",
        " 1) Filtros de calidad (Met N-terminal, repeticiones simples y dímeros).\n",
        " 2) Lanza TMbed (GPU) sobre el FASTA filtrado.\n",
        " 3) Filtra las predicciones para descartar todas las proteínas que tengan\n",
        "    al menos un dominio transmembrana (H/h/B/b) o signal peptide (S).\n",
        " 4) Guarda un CSV con las secuencias **sin** TM ni SP y reporta totales.\n",
        " 5) Genera un nuevo FASTA con las secuencias conservadas.\n",
        "\"\"\"\n",
        "\n",
        "import sys, os, csv, subprocess, tempfile\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Filtros de calidad\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def pop_if_dimer_repeat(sequence, seq_id, seq_dict):\n",
        "    for inicio in (0,1):\n",
        "        prev = sequence[inicio:inicio+2]; count=1\n",
        "        for i in range(inicio+2, len(sequence)-1, 2):\n",
        "            d = sequence[i:i+2]\n",
        "            if d == prev:\n",
        "                count += 1\n",
        "                if count >= 5:\n",
        "                    print(sequence)\n",
        "                    seq_dict.pop(seq_id, None)\n",
        "                    return True\n",
        "            else:\n",
        "                count = 1; prev = d\n",
        "    return False\n",
        "\n",
        "\n",
        "def pop_if_single_repeat(sequence, seq_id, seq_dict):\n",
        "    prev = sequence[0]; k = 1\n",
        "    for aa in sequence[1:]:\n",
        "        if aa == prev:\n",
        "            k += 1\n",
        "            if k >= 4:\n",
        "                seq_dict.pop(seq_id, None)\n",
        "                return True\n",
        "        else:\n",
        "            k = 1; prev = aa\n",
        "    return False\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Lectura FASTA y filtrado\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def load_fasta(path):\n",
        "    seqs = {}\n",
        "    sid = None\n",
        "    buf = []\n",
        "    for L in open(path):\n",
        "        if L.startswith(\">\"):\n",
        "            if sid:\n",
        "                seqs[sid] = \"\".join(buf).upper()\n",
        "            sid = L[1:].split()[0].strip()\n",
        "            buf = []\n",
        "        else:\n",
        "            buf.append(L.strip())\n",
        "    if sid:\n",
        "        seqs[sid] = \"\".join(buf).upper()\n",
        "    return seqs\n",
        "\n",
        "\n",
        "def quality_filter(seqs):\n",
        "    kept = seqs.copy()\n",
        "    for sid, seq in list(seqs.items()):\n",
        "        if not seq.startswith(\"M\"):\n",
        "            kept.pop(sid, None); continue\n",
        "        if pop_if_single_repeat(seq, sid, kept):\n",
        "            continue\n",
        "        pop_if_dimer_repeat(seq, sid, kept)\n",
        "    return kept\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# EJECUCIÓN de TMbed\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def run_tmbed(fasta, out_pred):\n",
        "    cmd = [\n",
        "        \"tmbed\", \"predict\",\n",
        "        \"--fasta\", fasta,\n",
        "        \"--predictions\", out_pred,\n",
        "        \"--use-gpu\",\n",
        "        \"--out-format\", \"0\"\n",
        "    ]\n",
        "    subprocess.run(cmd, check=True)\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Parseo y filtrado de predicciones\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def summarize_and_filter(pred_file, out_csv):\n",
        "    total = discarded = kept = 0\n",
        "    kept_ids = []\n",
        "    with open(pred_file) as f, open(out_csv, \"w\", newline=\"\") as out:\n",
        "        w = csv.writer(out)\n",
        "        w.writerow([\"id\",\"has_TM\",\"has_SP\"])\n",
        "        while True:\n",
        "            header = f.readline().strip()\n",
        "            if not header:\n",
        "                break\n",
        "            _seq = f.readline()\n",
        "            labels = f.readline().strip()\n",
        "            pid = header[1:]\n",
        "            has_tm = any(c in labels for c in \"HhBb\")\n",
        "            has_sp = \"S\" in labels\n",
        "            total += 1\n",
        "            if has_tm or has_sp:\n",
        "                discarded += 1\n",
        "            else:\n",
        "                kept += 1\n",
        "                kept_ids.append(pid)\n",
        "                w.writerow([pid, 0, 0])\n",
        "    return total, discarded, kept, kept_ids\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Main pipeline\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def main():\n",
        "    if len(sys.argv) < 2:\n",
        "        sys.exit(__doc__)\n",
        "    inp_fasta = \"/content/progen3_sequences_conserved.fasta\"\n",
        "    out_root  = \"results\"\n",
        "    os.makedirs(out_root, exist_ok=True)\n",
        "\n",
        "    # 1) Carga y filtra\n",
        "    seqs = load_fasta(inp_fasta)\n",
        "    print(f\"[INFO] Secuencias totales: {len(seqs)}\")\n",
        "    seqs2 = quality_filter(seqs)\n",
        "    print(f\"[INFO] Tras filtros calidad: {len(seqs2)} \"\n",
        "          f\"(descartadas {len(seqs)-len(seqs2)})\")\n",
        "\n",
        "    # 2) FASTA temporal filtrado\n",
        "    with tempfile.TemporaryDirectory() as td:\n",
        "        filt_fasta = os.path.join(td, \"filtered.fasta\")\n",
        "        with open(filt_fasta, \"w\") as fh:\n",
        "            for sid, seq in seqs2.items():\n",
        "                fh.write(f\">{sid}\\n{seq}\\n\")\n",
        "\n",
        "        # 3) Ejecuta TMbed\n",
        "        pred_file = os.path.join(out_root, \"tmbed.pred\")\n",
        "        print(\"[INFO] Ejecutando TMbed...\")\n",
        "        run_tmbed(filt_fasta, pred_file)\n",
        "\n",
        "    # 4) Filtra predicciones y resume\n",
        "    summary_csv = os.path.join(out_root, \"filtered_summary.csv\")\n",
        "    total, discarded, kept, kept_ids = summarize_and_filter(pred_file, summary_csv)\n",
        "\n",
        "    # 5) Genera nuevo FASTA con secuencias conservadas\n",
        "    kept_fasta = os.path.join(out_root, \"kept_sequences.fasta\")\n",
        "    with open(kept_fasta, \"w\") as fh:\n",
        "        for pid in kept_ids:\n",
        "            fh.write(f\">{pid}\\n{seqs2[pid]}\\n\")\n",
        "\n",
        "    # 6) Informar al usuario\n",
        "    print(f\"[OK] Todos los resultados en '{out_root}':\")\n",
        "    print(f\"  - Predicción TMbed   : {pred_file}\")\n",
        "    print(f\"  - Resumen CSV        : {summary_csv}\")\n",
        "    print(f\"  - FASTA conservadas  : {kept_fasta}\")\n",
        "    print(f\"  - Total procesadas   : {total}\")\n",
        "    print(f\"  - Descartadas (TM/SP): {discarded}\")\n",
        "    print(f\"  - Conservar          : {kept}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qs--yg-bipch"
      },
      "outputs": [],
      "source": [
        "!pip install fair-esm\n",
        "!pip install biopython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8PxzA4qiwYN"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import Union, List, Optional\n",
        "import torch, numpy as np\n",
        "from esm import FastaBatchedDataset, pretrained\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def extract_embeddings_chunked(\n",
        "    model_name: str,\n",
        "    fasta_file: Union[str, Path],\n",
        "    output_dir: Union[str, Path],\n",
        "    tokens_per_batch: int = 3000,\n",
        "    seq_length: int = 1022,\n",
        "    repr_layer: int = 33,\n",
        "    batches_per_file: int = 1000,   # ⬅️ guarda cada 1 000 batches\n",
        "):\n",
        "    fasta_file = Path(fasta_file)\n",
        "    output_dir = Path(output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # 1) Modelo\n",
        "    model, alphabet = pretrained.load_model_and_alphabet(model_name)\n",
        "    model.eval()\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "\n",
        "    # 2) DataLoader\n",
        "    dataset  = FastaBatchedDataset.from_file(str(fasta_file))\n",
        "    batches  = dataset.get_batch_indices(tokens_per_batch, extra_toks_per_seq=1)\n",
        "    collate  = alphabet.get_batch_converter(seq_length)\n",
        "    loader   = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_sampler=batches,\n",
        "        collate_fn=collate,\n",
        "        num_workers=4,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    # 3) Buffers para acumular hasta batches_per_file\n",
        "    buf_ids, buf_embs = [], []\n",
        "    chunk_idx = 0         # número de archivo guardado\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for bidx, (labels, strs, toks) in enumerate(tqdm(loader, desc=\"Batches\")):\n",
        "            if torch.cuda.is_available():\n",
        "                toks = toks.cuda(non_blocking=True)\n",
        "\n",
        "            out = model(toks, repr_layers=[repr_layer], return_contacts=False)\n",
        "            rep = out[\"representations\"][repr_layer]   # (B, L+1, 1280)\n",
        "\n",
        "            # → emb medio por secuencia\n",
        "            for i, label in enumerate(labels):\n",
        "                entry_id = label.split()[0]\n",
        "                L = min(seq_length, len(strs[i]))\n",
        "                emb = rep[i, 1:L+1].mean(0).detach().cpu()   # 1 280-D\n",
        "\n",
        "                buf_ids.append(entry_id)\n",
        "                buf_embs.append(emb)\n",
        "\n",
        "            # ¿Hemos llegado a batches_per_file?\n",
        "            if (bidx + 1) % batches_per_file == 0:\n",
        "                _save_chunk(buf_ids, buf_embs, output_dir, chunk_idx)\n",
        "                chunk_idx += 1\n",
        "                buf_ids, buf_embs = [], []        # vacía buffers\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        # Al terminar, guarda lo que quede (último trozo)\n",
        "        if buf_ids:\n",
        "            _save_chunk(buf_ids, buf_embs, output_dir, chunk_idx)\n",
        "\n",
        "\n",
        "def _save_chunk(ids: List[str], embs: List[torch.Tensor], outdir: Path, idx: int):\n",
        "    \"\"\"Convierte a numpy y guarda chunk_{idx}.npz\"\"\"\n",
        "    X = torch.stack(embs).numpy().astype(\"float32\")   # (n,1280)\n",
        "    np.savez_compressed(outdir / f\"chunk_{idx:04d}.npz\",\n",
        "                        ids=np.array(ids),\n",
        "                        X=X)\n",
        "    print(f\"🔹 Guardado chunk_{idx:04d}.npz  ({len(ids)} secuencias)\")\n",
        "\n",
        "import sys\n",
        "model_name = 'esm2_t33_650M_UR50D'\n",
        "fasta_file = \"/content/kept_sequences.fasta\"\n",
        "output_dir = 'immunology_prediction'\n",
        "extract_embeddings_chunked(model_name, fasta_file, output_dir)\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Directorios y nombres\n",
        "emb_dir = \"/content/immunology_prediction\"   # donde están chunk_000*.npz\n",
        "out_dir = \"/content/\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "final_name = \"protein_embeddings\"      # fichero final: unlabeled_ESM_ALL.npz\n",
        "\n",
        "# Buffers\n",
        "all_ids, all_X, chunk_index = [], [], []\n",
        "\n",
        "# Recorre todos los .npz ordenados\n",
        "npz_files = sorted(f for f in os.listdir(emb_dir) if f.endswith(\".npz\"))\n",
        "\n",
        "for idx, fname in enumerate(npz_files, 1):\n",
        "    path = os.path.join(emb_dir, fname)\n",
        "    print(f\"Cargando {idx}/{len(npz_files)} → {fname}\")\n",
        "\n",
        "    data = np.load(path, allow_pickle=False)\n",
        "    X_chunk  = data[\"X\"]\n",
        "    ids_chunk = data[\"ids\"]\n",
        "\n",
        "    all_X.append(X_chunk)\n",
        "    all_ids.append(ids_chunk)\n",
        "    chunk_index.append(np.full(len(ids_chunk), idx-1, dtype=np.int16))  # opcional\n",
        "\n",
        "# Concatenar todo\n",
        "X_final   = np.vstack(all_X)             # (N,1280)\n",
        "ids_final = np.concatenate(all_ids)      # (N,)\n",
        "\n",
        "# Guardar\n",
        "out_path = os.path.join(out_dir, f\"{final_name}.npz\")\n",
        "np.savez_compressed(out_path,\n",
        "                    X=X_final,\n",
        "                    ids=ids_final,\n",
        "                    chunks=np.concatenate(chunk_index))   # 'chunks' es opcional\n",
        "\n",
        "print(f\"\\n✔️  Guardado archivo único: {out_path}\")\n",
        "print(\"   Embeddings totales:\", X_final.shape[0])\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "from Bio import SeqIO  # pip install biopython\n",
        "\n",
        "# 1) Carga el modelo y predice\n",
        "modelo_immun = load_model('immupig_epoch500.keras')\n",
        "probs = modelo_immun.predict(X_final).ravel()   # shape (n,)\n",
        "\n",
        "# ids_final: lista o array de identificadores (strings) para cada fila de X_final\n",
        "\n",
        "# 2) DataFrame y CSV\n",
        "df = pd.DataFrame({\n",
        "    'id':    ids_final,\n",
        "    'score': probs\n",
        "})\n",
        "df.to_csv('scores_immupig.csv', index=False)\n",
        "print(\"CSV escrito: scores_immupig.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boJLj3WKizPQ"
      },
      "outputs": [],
      "source": [
        "# 3) Filtrar FASTA según umbral\n",
        "threshold = 0.5\n",
        "# crear un set con los ids que cumplen score > 0.5\n",
        "ids_bajos = set(df.loc[df['score'] > threshold, 'id'])\n",
        "\n",
        "total = 0\n",
        "kept  = 0\n",
        "output_fasta=\"immuno_sequences.fasta\"\n",
        "with open(output_fasta, 'w') as out_f:\n",
        "    for rec in SeqIO.parse(fasta_file, 'fasta'):\n",
        "        total += 1\n",
        "        if rec.id in ids_bajos:\n",
        "            SeqIO.write(rec, out_f, 'fasta')\n",
        "            kept += 1\n",
        "\n",
        "discarded = total - kept\n",
        "\n",
        "print(f\"Secuencias originales: {total}\")\n",
        "print(f\"Secuencias mantenidas (score > {threshold}): {kept}\")\n",
        "print(f\"Secuencias descartadas: {discarded}\")\n",
        "print(f\"FASTAs filtrados escritos en: {output_fasta}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}